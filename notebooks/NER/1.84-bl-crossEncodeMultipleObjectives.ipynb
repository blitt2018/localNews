{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Article Similarity Modelling\n",
    "- Cross encoding \n",
    "- Translated data \n",
    "- Using Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch \n",
    "import random\n",
    "from torch import nn\n",
    "from transformers import RobertaTokenizer, PreTrainedTokenizer, DistilBertTokenizer, DistilBertModel, RobertaModel\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn import CosineEmbeddingLoss\n",
    "import transformers\n",
    "import seaborn as sns\n",
    "#Build up to SBERT model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviceNum = 0\n",
    "device = torch.device(\"cuda:\" + str(deviceNum) if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.memory_allocated: 0.000000GB\n",
      "torch.cuda.memory_reserved: 0.000000GB\n",
      "torch.cuda.memory_free: 0.000000GB\n",
      "torch.cuda.max_memory_reserved: 0.000000GB\n"
     ]
    }
   ],
   "source": [
    "def check_mem():\n",
    "    torch.cuda.empty_cache()\n",
    "    a = torch.cuda.memory_allocated(deviceNum)/1024/1024/1024\n",
    "    r = torch.cuda.memory_reserved(deviceNum)/1024/1024/1024\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%a)\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%r)\n",
    "    print(\"torch.cuda.memory_free: %fGB\"%(r-a))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(deviceNum)/1024/1024/1024))\n",
    "check_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seeds \n",
    "torch.manual_seed(85)\n",
    "random.seed(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/shared/3/projects/benlitterer/localNews/NetworkMVP/translatedCleaned.tsv\", sep=\"\\t\")\n",
    "#df = df.loc[(df[\"url1_lang\"] == \"en\") & (df[\"url2_lang\"] == \"en\")]\n",
    "\n",
    "groundTruths = [\"Geography\", \"Entities\",\"Narrative\", \"Overall\"]\n",
    "features = ['text1', 'text2', 'title1', 'title2', 'url1_lang', 'url2_lang']\n",
    "toSelect = groundTruths + features \n",
    "\n",
    "#get only the columns we need \n",
    "#TODO: do we need \"pair_id\"? \n",
    "leanDf = df[toSelect].dropna()\n",
    "\n",
    "#rescale data from (0, 4): (0, 1)\n",
    "for colName in groundTruths: \n",
    "    leanDf[colName] = 1 - ((leanDf[colName] - 1) / 3)\n",
    "\n",
    "#reset index so it is contiguous set of numbers \n",
    "leanDf = leanDf.reset_index(drop=True)\n",
    "\n",
    "#now combine title and text together \n",
    "#first add \". \" to title \n",
    "leanDf[\"title1\"] = leanDf[\"title1\"].apply(lambda x: x + \". \")\n",
    "leanDf[\"title2\"] = leanDf[\"title2\"].apply(lambda x: x + \". \")\n",
    "\n",
    "leanDf[\"text1\"] = leanDf[\"title1\"] + leanDf[\"text1\"]\n",
    "leanDf[\"text2\"] = leanDf[\"title2\"] + leanDf[\"text2\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'url1_lang', 'url2_lang', 'pair_id', 'link1', 'link2',\n",
       "       'ia_link1', 'ia_link2', 'Geography', 'Entities', 'Time', 'Narrative',\n",
       "       'Overall', 'Style', 'Tone', 'id1', 'id2', 'ogText1', 'ogTitle1',\n",
       "       'ogText2', 'ogTitle2', 'text1', 'title1', 'text2', 'title2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    2296\n",
       "de     845\n",
       "es     560\n",
       "tr     455\n",
       "pl     310\n",
       "ar     268\n",
       "fr      72\n",
       "Name: url2_lang, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leanDf[\"url2_lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: do a language cutoff \n",
    "langList = [\"en\", \"fr\", \"es\"]\n",
    "leanDf = leanDf[(leanDf[\"url1_lang\"].isin(langList)) & (leanDf[\"url2_lang\"].isin(langList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-f73c78befe86>:13: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  trainDf = leanDf.loc[set(leanDf.index) - set(validIndices)]\n"
     ]
    }
   ],
   "source": [
    "#we only want to sample validation data from the pairs that are both english \n",
    "enDf = leanDf[(leanDf[\"url1_lang\"] == \"en\") & (leanDf[\"url2_lang\"] == \"en\")]\n",
    "validProp = .1\n",
    "validCount = int(validProp * len(enDf))\n",
    "print(validCount)\n",
    "validIndices = random.sample(list(enDf.index), validCount)\n",
    "\n",
    "#get dataframe with indices of only the original english pairs \n",
    "validDf = enDf.loc[validIndices]\n",
    "\n",
    "#train data should be all rows that aren't in the validation set \n",
    "#here we are taking a set difference and then indexing what remains \n",
    "trainDf = leanDf.loc[set(leanDf.index) - set(validIndices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data loaded in properly \n",
    "trainDataset = Dataset.from_pandas(trainDf)\n",
    "validDataset = Dataset.from_pandas(validDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link: https://huggingface.co/sentence-transformers/all-mpnet-base-v2\n",
    "#example of tokenizing \n",
    "#tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-mpnet-base-v2')\n",
    "#tokenizer = AutoTokenizer.from_pretrained('Giyaseddin/distilbert-base-cased-finetuned-fake-and-real-news-dataset')\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just Sanity checking the special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (677 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Virginia man arre'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer(trainDataset[0][\"text1\"], trainDataset[0][\"text2\"])\n",
    "tokenizer.decode(encoded[\"input_ids\"])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s>Zomato Buys Uber'\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer(trainDataset[3][\"text1\"], trainDataset[3][\"text2\"])\n",
    "tokenizer.decode(encoded[\"input_ids\"])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making sure that only_first works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 42891, 232, 42, 2, 2, 23075, 6, 8, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = \"hello world this is the first part\" \n",
    "second = \"OPE, and I think this will be the second\"\n",
    "encoded = tokenizer(first, second, truncation=\"longest_first\",  max_length=10)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12664e5be05a4340aae10b99617607ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2197 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7e91659635454dae725e71c2d4570c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/173 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "trainDataset = trainDataset.map(lambda x: tokenizer(x[\"text1\"], x[\"text2\"], max_length=500, padding=\"max_length\", truncation=True))\n",
    "validDataset = validDataset.map(lambda x: tokenizer(x[\"text1\"], x[\"text2\"], max_length=500, padding=\"max_length\", truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only need the input information \n",
    "trainDataset = trainDataset.remove_columns([\"text1\", \"text2\", \"__index_level_0__\"])\n",
    "validDataset = validDataset.remove_columns([\"text1\", \"text2\", \"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataset features to PyTorch tensors\n",
    "formatColumns = groundTruths + [\"input_ids\", \"attention_mask\"]\n",
    "validDataset.set_format(type='torch', columns=formatColumns)\n",
    "trainDataset.set_format(type='torch', columns=formatColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataloader\n",
    "batch_size = 8\n",
    "trainLoader = torch.utils.data.DataLoader(\n",
    "    trainDataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "validLoader = torch.utils.data.DataLoader(\n",
    "    validDataset, batch_size=1, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDropModel(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(RDropModel,self).__init__()\n",
    "        self.model = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.GELU = nn.GELU\n",
    "        self.dropout = nn.Dropout(.25)\n",
    "        self.l1 = nn.Linear(768, 512).to(device)\n",
    "        #self.l2 = nn.Linear(500, 250).to(device)\n",
    "        self.l3 = nn.Linear(512, 4).to(device)\n",
    "        self.loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, attention_mask): \n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask): \n",
    "    \n",
    "        #encode sentence and get mean pooled sentence representation \n",
    "        encoding = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        #Debugging: print(encoding.squeeze().shape)\n",
    "        \n",
    "        print(\"raw encoding\")\n",
    "        print(encoding.size())\n",
    "        \n",
    "        #squeeze to remove extra dimension. Gives us 500 x 750 \n",
    "        #first one is cls token \n",
    "        meanPooled = self.mean_pooling(encoding, attention_mask)\n",
    "        \n",
    "        print(\"mean pooled\")\n",
    "        print(meanPooled.size())\n",
    "        \n",
    "        #NOTE: Since dropout is random we simply send data through twice \n",
    "        #to get two predictions that have some noise \n",
    "        out = self.l1(meanPooled)\n",
    "        out = self.ReLU(out)\n",
    "       \n",
    "        #out = self.l2(out)\n",
    "        #out = self.GELU(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        pred1 = self.l3(out)\n",
    "        \n",
    "        #print(\"pred1 shape\")\n",
    "        #print(pred1.shape)\n",
    "        \n",
    "        encoding = self.model(input_ids, attention_mask=attention_mask)[0]  #all token embeddings\n",
    "        \n",
    "        #squeeze to remove extra dimension. Gives us 500 x 750\n",
    "        #first one is cls token \n",
    "        meanPooled = self.mean_pooling(encoding, attention_mask)\n",
    "        \n",
    "        #NOTE: Since dropout is random we simply send data through twice \n",
    "        #to get two predictions that have some noise \n",
    "        out = self.l1(meanPooled)\n",
    "        out = self.ReLU(out)\n",
    "        \n",
    "        #out = self.l2(out)\n",
    "        #out = self.ReLU(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        pred2 = self.l3(out)\n",
    "        return pred1, pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RDropModel().to(device)\n",
    "\n",
    "#TODO: double check on if reduction=\"mean\" is the right move here...\n",
    "#could cosine similarity also work..? I think that is between the two predicted vectors though.. \n",
    "loss_func = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "trainLen = len(trainDataset)\n",
    "\n",
    "# we would initialize everything first\n",
    "optim = torch.optim.Adam(model.parameters(), lr=5e-6)\n",
    "\n",
    "REG_ALPHA = .3\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int((trainLen*EPOCHS) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=warmup_steps, num_training_steps=total_steps - warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npredEx = torch.tensor([[1.0000, 0.2222, 0.9444, 0.6667, 0.0000, 0.0000, 0.1111, 1.0000, 1.0000,\\n         1.0000]])\\ngtEx = torch.tensor([[.5, , -0.0629, -0.0781, -0.0352, -0.0591, -0.0396, -0.0552,\\n         -0.0397, -0.0494]])\\nloss_func(predEx, gtEx)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test out loss function since it seems like something weird is going on \n",
    "\"\"\"\n",
    "predEx = torch.tensor([[1.0000, 0.2222, 0.9444, 0.6667, 0.0000, 0.0000, 0.1111, 1.0000, 1.0000,\n",
    "         1.0000]])\n",
    "gtEx = torch.tensor([[.5, , -0.0629, -0.0781, -0.0352, -0.0591, -0.0396, -0.0552,\n",
    "         -0.0397, -0.0494]])\n",
    "loss_func(predEx, gtEx)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography', 'Entities', 'Narrative', 'Overall']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundTruths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the loss across multiple different objectives. \n",
    "Since overall is most important it gets more weight. \n",
    "\"\"\"\n",
    "def getWeightedLoss(predTens, gtTens):\n",
    "    #try getting rid of Tone and Style \n",
    "    LOSS_WEIGHTS = [.1, .1, .1, .7]\n",
    "    loss = 0.0\n",
    "    for i in range(len(LOSS_WEIGHTS)): \n",
    "        \n",
    "        #get ground truth value associated with this column name \n",
    "        currGT = gtTens[:, :, i]\n",
    "        \n",
    "        #TODO: figure out how to index properly here \n",
    "        pred = predTens[:, :, i]\n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"pred\")\n",
    "        print(pred)\n",
    "        print(pred.shape)\n",
    "        print(\"GT\")\n",
    "        print(currGT)\n",
    "        print(currGT.shape)\n",
    "        \"\"\"\n",
    "        #get loss \n",
    "        loss += (loss_func(pred, currGT) * LOSS_WEIGHTS[i])\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(): \n",
    "    model.eval()\n",
    "    lossList = []\n",
    "    pred = []\n",
    "    GT = []\n",
    "\n",
    "    i = True \n",
    "    for batch in validLoader: \n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        #label = batch['ground_truth'].to(device).unsqueeze(1)\n",
    "\n",
    "        #send batch info through model \n",
    "        pred1, pred2 = model(input_ids, attention_mask)\n",
    "        pred1 = pred1.unsqueeze(0)\n",
    "        pred2 = pred2.unsqueeze(0)\n",
    "        \n",
    "        gts = torch.stack([batch[colName] for colName in groundTruths], 0).to(device).T.unsqueeze(0)\n",
    "        \n",
    "        #get wegihted loss relating to label prediction \n",
    "        loss1 = getWeightedLoss(gts, pred1)\n",
    "        loss2 = getWeightedLoss(gts, pred2)\n",
    "        loss_b = .5*(loss1 + loss2)\n",
    "        \n",
    "        #get loss relating to invariance to dropout \n",
    "        #NOTE:\n",
    "        loss_r = getWeightedLoss(pred1, pred2)\n",
    "        \n",
    "        #combine losses with alpha hyperparam \n",
    "        loss = REG_ALPHA*loss_r + (1-REG_ALPHA)*loss_b\n",
    "        \n",
    "        #get output metrics \n",
    "        lossList.append(loss.item())\n",
    "        pred.append([float(item) for item in list(pred1.squeeze())])\n",
    "        GT.append([float(item) for item in list(gts.squeeze())])\n",
    "        \n",
    "        if not (len(lossList) == len(pred) == len(pred)):\n",
    "            print(\"lens not equal\")\n",
    "    #print(vGT)\n",
    "    return [lossList, pred, GT]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e272721f80d4b4cafce5df58354e466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting validation\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n",
      "raw encoding\n",
      "torch.Size([1, 500, 768])\n",
      "mean pooled\n",
      "torch.Size([1, 768])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-25-8d15a7f3ce3c&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-24-378fccd7b959&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validation</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-19-30a987e58fef&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">47</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">848</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 845 │   │   │   </span>inputs_embeds=inputs_embeds,                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 846 │   │   │   </span>past_key_values_length=past_key_values_length,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 847 │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 848 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>encoder_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoder(                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 849 │   │   │   </span>embedding_output,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850 │   │   │   </span>attention_mask=extended_attention_mask,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 851 │   │   │   </span>head_mask=head_mask,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">524</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 521 │   │   │   │   │   </span>encoder_attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 522 │   │   │   │   </span>)                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 523 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 524 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = layer_module(                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 525 │   │   │   │   │   </span>hidden_states,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 526 │   │   │   │   │   </span>attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 527 │   │   │   │   │   </span>layer_head_mask,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">409</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 406 │   </span>) -&gt; Tuple[torch.Tensor]:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 407 │   │   # decoder uni-directional self-attention cached key/values tuple is at pos</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 408 │   │   </span>self_attn_past_key_value = past_key_value[:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> past_key_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">Non</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 409 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>self_attention_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.attention(                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 │   │   │   </span>hidden_states,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 │   │   │   </span>attention_mask,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 │   │   │   </span>head_mask,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">336</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 333 │   │   </span>past_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 334 │   │   </span>output_attentions: Optional[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">bool</span>] = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 335 │   </span>) -&gt; Tuple[torch.Tensor]:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 336 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>self_outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.self(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 337 │   │   │   </span>hidden_states,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 338 │   │   │   </span>attention_mask,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 339 │   │   │   </span>head_mask,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1131</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1128 │   │   # this function, and just call forward.</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1129 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_h <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1130 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1131 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132 │   │   # Do not call functions when jit is used</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1133 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1134 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_roberta.py</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> :<span style=\"color: #0000ff; text-decoration-color: #0000ff\">222</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 219 │   │   │   </span>key_layer = torch.cat([past_key_value[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], key_layer], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 220 │   │   │   </span>value_layer = torch.cat([past_key_value[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>], value_layer], dim=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 221 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 222 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>key_layer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transpose_for_scores(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.key(hidden_states))         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 223 │   │   │   </span>value_layer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transpose_for_scores(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.value(hidden_states))     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 224 │   │   </span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 225 │   │   </span>query_layer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transpose_for_scores(mixed_query_layer)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-25-8d15a7f3ce3c>\u001b[0m:\u001b[94m16\u001b[0m in \u001b[92m<module>\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-24-378fccd7b959>\u001b[0m:\u001b[94m16\u001b[0m in \u001b[92mvalidation\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1131\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1131 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-19-30a987e58fef>\u001b[0m:\u001b[94m47\u001b[0m in \u001b[92mforward\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1131\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1131 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m848\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 845 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds=inputs_embeds,                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[2m│   │   │   \u001b[0mpast_key_values_length=past_key_values_length,                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 848 \u001b[2m│   │   \u001b[0mencoder_outputs = \u001b[96mself\u001b[0m.encoder(                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2m│   │   │   \u001b[0membedding_output,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=extended_attention_mask,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 851 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask=head_mask,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1131\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1131 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m524\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 521 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mencoder_attention_mask,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 522 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 523 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 524 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = layer_module(                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 525 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 526 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 527 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mlayer_head_mask,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1131\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1131 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m409\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2m│   \u001b[0m) -> Tuple[torch.Tensor]:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# decoder uni-directional self-attention cached key/values tuple is at pos\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 408 \u001b[0m\u001b[2m│   │   \u001b[0mself_attn_past_key_value = past_key_value[:\u001b[94m2\u001b[0m] \u001b[94mif\u001b[0m past_key_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNon\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 409 \u001b[2m│   │   \u001b[0mself_attention_outputs = \u001b[96mself\u001b[0m.attention(                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1131\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1131 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m336\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 333 \u001b[0m\u001b[2m│   │   \u001b[0mpast_key_value: Optional[Tuple[Tuple[torch.FloatTensor]]] = \u001b[94mNone\u001b[0m,          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 334 \u001b[0m\u001b[2m│   │   \u001b[0moutput_attentions: Optional[\u001b[96mbool\u001b[0m] = \u001b[94mFalse\u001b[0m,                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 335 \u001b[0m\u001b[2m│   \u001b[0m) -> Tuple[torch.Tensor]:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 336 \u001b[2m│   │   \u001b[0mself_outputs = \u001b[96mself\u001b[0m.self(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 337 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 338 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 339 \u001b[0m\u001b[2m│   │   │   \u001b[0mhead_mask,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1131\u001b[0m in \u001b[92m_call_impl\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1128 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_h \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1130 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1131 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1132 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1133 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1134 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/anaconda/lib/python3.9/site-packages/transformers/models/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m :\u001b[94m222\u001b[0m in \u001b[92mforward\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 219 \u001b[0m\u001b[2m│   │   │   \u001b[0mkey_layer = torch.cat([past_key_value[\u001b[94m0\u001b[0m], key_layer], dim=\u001b[94m2\u001b[0m)           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 220 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue_layer = torch.cat([past_key_value[\u001b[94m1\u001b[0m], value_layer], dim=\u001b[94m2\u001b[0m)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 221 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 222 \u001b[2m│   │   │   \u001b[0mkey_layer = \u001b[96mself\u001b[0m.transpose_for_scores(\u001b[96mself\u001b[0m.key(hidden_states))         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 223 \u001b[0m\u001b[2m│   │   │   \u001b[0mvalue_layer = \u001b[96mself\u001b[0m.transpose_for_scores(\u001b[96mself\u001b[0m.value(hidden_states))     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 224 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 225 \u001b[0m\u001b[2m│   │   \u001b[0mquery_layer = \u001b[96mself\u001b[0m.transpose_for_scores(mixed_query_layer)                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "trainDict = {}\n",
    "lossList = []\n",
    "validMetrics = []\n",
    "trainMetrics = []\n",
    "subLossList = []\n",
    "# increase from 1 epoch if need be \n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    model.train()  # make sure model is in training mode\n",
    "    \n",
    "    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n",
    "    loop = tqdm(trainLoader, leave=True)\n",
    "    \n",
    "    print(\"starting validation\")\n",
    "    validMetrics.append(validation())\n",
    "    print(\"finishing validation\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(loop): \n",
    "        # zero all gradients on each new step\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # prepare batches and more all to the active device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        \n",
    "        #send batch info through model \n",
    "        pred1, pred2 = model(input_ids, attention_mask)\n",
    "        pred1 = pred1.unsqueeze(0)\n",
    "        pred2 = pred2.unsqueeze(0)\n",
    "        \n",
    "        gts = torch.stack([batch[colName] for colName in groundTruths], 0).T.to(device).unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        #get loss relating to label prediction \n",
    "        loss1 = getWeightedLoss(gts, pred1)\n",
    "        loss2 = getWeightedLoss(gts, pred2)\n",
    "        loss_b = .5*(loss1 + loss2)\n",
    "        \n",
    "        #get loss relating to invariance to dropout \n",
    "        loss_r = getWeightedLoss(pred1, pred2)\n",
    "        \n",
    "        #combine losses with alpha hyperparam \n",
    "        loss = REG_ALPHA*loss_r + (1-REG_ALPHA)*loss_b\n",
    "        \n",
    "        # using loss, calculate gradients and then optimize\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        #get mean loss over last 20 batches \n",
    "        if i % 20 == 0 and i > 0: \n",
    "            #print(subLossList)\n",
    "            lossList.append(np.mean(subLossList))\n",
    "            subLossList = []\n",
    "        \n",
    "        subLossList.append(float(loss.item()))\n",
    "        \n",
    "        # update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # update the TDQM progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "validMetrics.append(validation())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train Loss')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossSmoothing = 20\n",
    "lossIndex = [(i * lossSmoothing)/275 for i in range(len(lossList))]\n",
    "plt.plot(lossIndex, lossList)\n",
    "plt.xlabel(\"Batch Num\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Train Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(validMetrics[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-3f433cc7889e>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  validArr = np.array(validMetrics)\n"
     ]
    }
   ],
   "source": [
    "#validArr = np.array(validMetrics[4])\n",
    "#print(validArr.shape)\n",
    "validArr = np.array(validMetrics)\n",
    "#validArr = validArr[5,:,:]\n",
    "#np.corrcoef(test[1], test[2])\n",
    "\n",
    "outDfList = []\n",
    "iterList = []\n",
    "corrList = []\n",
    "#go through each validation step\n",
    "\n",
    "for i in range(validArr.shape[0]): \n",
    "    print(i)\n",
    "    subDf = pd.DataFrame(validArr[i].T)\n",
    "    subDf.columns = [\"loss\", \"pred\", \"true\"]\n",
    "    \n",
    "\n",
    "    predCols = [\"pred\" + item for item in groundTruths]\n",
    "    gtCols = [\"gt\" + item for item in groundTruths]\n",
    "    \n",
    "    \n",
    "    subDf[predCols] = pd.DataFrame(subDf[\"pred\"].tolist(), index=subDf.index)\n",
    "    subDf[gtCols] = pd.DataFrame(subDf[\"true\"].tolist(), index=subDf.index)\n",
    "    \n",
    "    corrScores = []\n",
    "    for colName in groundTruths: \n",
    "        corr = np.corrcoef(subDf[\"pred\" + colName], subDf[\"gt\" + colName])[1, 0]\n",
    "        corrScores.append(corr)\n",
    "    corrList.append(corrScores)\n",
    "    \n",
    "corrDf = pd.DataFrame(corrList, columns=groundTruths)\n",
    "\n",
    "#plt.plot(iterList, corrList)\n",
    "#plt.xlabel(\"batch num\")\n",
    "#plt.ylabel(\"pearson correlation\")\n",
    "#plt.title(\"validation eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 173)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validArr[1:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Narrative</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.149120</td>\n",
       "      <td>0.068737</td>\n",
       "      <td>-0.248528</td>\n",
       "      <td>0.035040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.714452</td>\n",
       "      <td>0.795597</td>\n",
       "      <td>0.797646</td>\n",
       "      <td>0.841531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750122</td>\n",
       "      <td>0.827253</td>\n",
       "      <td>0.817953</td>\n",
       "      <td>0.868189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786643</td>\n",
       "      <td>0.842382</td>\n",
       "      <td>0.829971</td>\n",
       "      <td>0.886190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.783473</td>\n",
       "      <td>0.844447</td>\n",
       "      <td>0.829451</td>\n",
       "      <td>0.886646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geography  Entities  Narrative   Overall\n",
       "0  -0.149120  0.068737  -0.248528  0.035040\n",
       "1   0.714452  0.795597   0.797646  0.841531\n",
       "2   0.750122  0.827253   0.817953  0.868189\n",
       "3   0.786643  0.842382   0.829971  0.886190\n",
       "4   0.783473  0.844447   0.829451  0.886646"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7f79392d90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(data=corrDf)\n",
    "plt.title(\"Training Over all Objectives\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, EPOCHS)\n",
    "#Grabbed this line from: https://www.statology.org/seaborn-legend-outside/\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'prediction')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(subDf[\"gtOverall\"], subDf[\"predOverall\"], alpha = .2)\n",
    "plt.title(\"'Overall' predicted vs. ground truth \")\n",
    "plt.xlabel(\"ground truth\")\n",
    "plt.ylabel(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(label)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func(x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainDf[\"testLoss\"].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
